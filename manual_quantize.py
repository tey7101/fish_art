# -*- coding: utf-8 -*-
"""
æ‰‹åŠ¨é‡åŒ–ONNXæ¨¡å‹
é€šè¿‡è½¬æ¢æƒé‡ç²¾åº¦æ¥å‡å°æ¨¡å‹å¤§å°
"""

import os
import sys
import io

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º UTF-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

try:
    import onnx
    from onnx import numpy_helper
    import numpy as np
except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘ä¾èµ–åº“ - {e}")
    print("\nè¯·å…ˆå®‰è£…ä¾èµ–ï¼š")
    print("pip install onnx numpy")
    sys.exit(1)

def quantize_weights_float16(input_model_path, output_model_path):
    """
    å°†æ¨¡å‹æƒé‡ä» float32 è½¬æ¢ä¸º float16
    å¯ä»¥å‡å°çº¦ 50% çš„æ¨¡å‹å¤§å°
    """
    print("=" * 60)
    print("ğŸŸ Fish Doodle Classifier - Float16 æƒé‡é‡åŒ–å·¥å…·")
    print("=" * 60)
    print(f"\nğŸ“ è¾“å…¥æ¨¡å‹: {input_model_path}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_model_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {input_model_path}")
        sys.exit(1)
    
    # è·å–åŸå§‹æ¨¡å‹å¤§å°
    original_size = os.path.getsize(input_model_path) / (1024 * 1024)
    print(f"ğŸ“Š åŸå§‹æ¨¡å‹å¤§å°: {original_size:.2f} MB")
    
    # åŠ è½½æ¨¡å‹
    print("\nâš™ï¸  æ­£åœ¨åŠ è½½æ¨¡å‹...")
    try:
        model = onnx.load(input_model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # è½¬æ¢æƒé‡ä¸º float16
    print("\nâš™ï¸  æ­£åœ¨å°†æƒé‡ä» float32 è½¬æ¢ä¸º float16...")
    converted_count = 0
    
    for tensor in model.graph.initializer:
        if tensor.data_type == onnx.TensorProto.FLOAT:
            # è·å–åŸå§‹æƒé‡æ•°æ®
            float32_data = numpy_helper.to_array(tensor)
            
            # è½¬æ¢ä¸º float16
            float16_data = float32_data.astype(np.float16)
            
            # æ›´æ–° tensor
            tensor.ClearField('float_data')
            tensor.ClearField('raw_data')
            tensor.data_type = onnx.TensorProto.FLOAT16
            tensor.raw_data = float16_data.tobytes()
            
            converted_count += 1
    
    print(f"âœ… å·²è½¬æ¢ {converted_count} ä¸ªæƒé‡å¼ é‡")
    
    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜é‡åŒ–æ¨¡å‹åˆ°: {output_model_path}")
    try:
        onnx.save(model, output_model_path)
        print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ¨¡å‹å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # è·å–é‡åŒ–åæ¨¡å‹å¤§å°
    quantized_size = os.path.getsize(output_model_path) / (1024 * 1024)
    reduction = ((original_size - quantized_size) / original_size * 100)
    
    print(f"\nğŸ“Š é‡åŒ–ç»“æœ:")
    print(f"   åŸå§‹å¤§å°:  {original_size:.2f} MB")
    print(f"   é‡åŒ–å¤§å°:  {quantized_size:.2f} MB")
    print(f"   å‡å°æ¯”ä¾‹:  {reduction:.1f}%")
    print(f"   èŠ‚çœç©ºé—´:  {original_size - quantized_size:.2f} MB")
    
    # éªŒè¯æ¨¡å‹
    print("\nğŸ” éªŒè¯é‡åŒ–åçš„æ¨¡å‹...")
    try:
        test_model = onnx.load(output_model_path)
        onnx.checker.check_model(test_model)
        print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡ï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # ç½‘ç»œæ€§èƒ½ä¼°ç®—
    print("\nğŸ“¡ ç½‘ç»œåŠ è½½æ—¶é—´ä¼°ç®—:")
    print(f"   å¿«é€Ÿ WiFi (50 Mbps):  ~{quantized_size * 8 / 50:.1f} ç§’")
    print(f"   4G ç½‘ç»œ (10 Mbps):     ~{quantized_size * 8 / 10:.1f} ç§’")
    print(f"   æ…¢é€Ÿ 3G (1 Mbps):      ~{quantized_size * 8 / 1 / 60:.1f} åˆ†é’Ÿ")
    
    print("\n" + "=" * 60)
    print("âœ¨ å®Œæˆï¼")
    print("=" * 60)
    
    print("\nğŸ’¡ è¯´æ˜:")
    print("   - Float16 é‡åŒ–é€šå¸¸å¯å‡å° 50% å¤§å°")
    print("   - ç²¾åº¦æŸå¤±æå°ï¼ˆ< 0.1%ï¼‰")
    print("   - å¹¿æ³›æ”¯æŒï¼Œå…¼å®¹æ€§å¥½")
    print("   - å¦‚éœ€æ›´å°çš„æ¨¡å‹ï¼Œè€ƒè™‘ INT8 é‡åŒ–ï¼ˆéœ€è¦ onnxruntimeï¼‰")

if __name__ == "__main__":
    input_model = "fish_doodle_classifier.onnx"
    output_model = "fish_doodle_classifier_float16.onnx"
    
    quantize_weights_float16(input_model, output_model)


