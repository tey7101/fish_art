#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ONNX æ¨¡å‹ INT8 é‡åŒ–è„šæœ¬
å°† fish_doodle_classifier.onnx (42.63 MB) é‡åŒ–ä¸º INT8 æ ¼å¼
é¢„æœŸå‡å°çº¦ 75% çš„å¤§å°
"""

import os
import sys
import io

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º UTF-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

try:
    from onnxruntime.quantization import quantize_dynamic, QuantType
    import onnx
except ImportError:
    print("âŒ ç¼ºå°‘ä¾èµ–åº“ï¼")
    print("\nè¯·å…ˆå®‰è£…ä¾èµ–ï¼š")
    print("pip install onnxruntime onnx")
    sys.exit(1)

def quantize_model(input_model, output_model):
    """
    ä½¿ç”¨åŠ¨æ€é‡åŒ–å°†æ¨¡å‹ä» FP32 è½¬æ¢ä¸º INT8
    """
    print("ğŸ”§ å¼€å§‹é‡åŒ–æ¨¡å‹...")
    print(f"ğŸ“ è¾“å…¥æ¨¡å‹: {input_model}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_model):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {input_model}")
        sys.exit(1)
    
    # è·å–åŸå§‹æ¨¡å‹å¤§å°
    original_size = os.path.getsize(input_model) / (1024 * 1024)
    print(f"ğŸ“Š åŸå§‹æ¨¡å‹å¤§å°: {original_size:.2f} MB")
    
    # æ‰§è¡ŒåŠ¨æ€é‡åŒ–
    print("\nâš™ï¸  æ­£åœ¨æ‰§è¡Œ INT8 é‡åŒ–ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    try:
        quantize_dynamic(
            model_input=input_model,
            model_output=output_model,
            weight_type=QuantType.QUInt8,  # æ— ç¬¦å· 8 ä½æ•´æ•°
            optimize_model=True  # åŒæ—¶è¿›è¡Œå›¾ä¼˜åŒ–
        )
        print("âœ… é‡åŒ–å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ é‡åŒ–å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # è·å–é‡åŒ–åæ¨¡å‹å¤§å°
    quantized_size = os.path.getsize(output_model) / (1024 * 1024)
    reduction = ((original_size - quantized_size) / original_size * 100)
    
    print(f"\nğŸ“Š é‡åŒ–ç»“æœ:")
    print(f"   åŸå§‹å¤§å°:  {original_size:.2f} MB")
    print(f"   é‡åŒ–å¤§å°:  {quantized_size:.2f} MB")
    print(f"   å‡å°æ¯”ä¾‹:  {reduction:.1f}%")
    print(f"   èŠ‚çœç©ºé—´:  {original_size - quantized_size:.2f} MB")
    
    # éªŒè¯æ¨¡å‹æ–‡ä»¶
    print("\nğŸ” éªŒè¯é‡åŒ–åçš„æ¨¡å‹...")
    try:
        model = onnx.load(output_model)
        onnx.checker.check_model(model)
        print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡ï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    print(f"\nğŸ‰ æˆåŠŸï¼é‡åŒ–æ¨¡å‹å·²ä¿å­˜åˆ°: {output_model}")
    
    # ç½‘ç»œæ€§èƒ½ä¼°ç®—
    print("\nğŸ“¡ ç½‘ç»œåŠ è½½æ—¶é—´ä¼°ç®—:")
    print(f"   å¿«é€Ÿ WiFi (50 Mbps):  ~{quantized_size * 8 / 50:.1f} ç§’")
    print(f"   4G ç½‘ç»œ (10 Mbps):     ~{quantized_size * 8 / 10:.1f} ç§’")
    print(f"   æ…¢é€Ÿ 3G (1 Mbps):      ~{quantized_size * 8 / 1 / 60:.1f} åˆ†é’Ÿ")

if __name__ == "__main__":
    # è¾“å…¥è¾“å‡ºæ–‡ä»¶å
    input_model = "fish_doodle_classifier.onnx"
    output_model = "fish_doodle_classifier_int8.onnx"
    
    print("=" * 60)
    print("ğŸŸ Fish Doodle Classifier - ONNX æ¨¡å‹é‡åŒ–å·¥å…·")
    print("=" * 60)
    
    quantize_model(input_model, output_model)
    
    print("\n" + "=" * 60)
    print("âœ¨ å®Œæˆï¼æ‚¨å¯ä»¥ä½¿ç”¨é‡åŒ–åçš„æ¨¡å‹æ›¿æ¢åŸæ¨¡å‹ã€‚")
    print("=" * 60)

