# -*- coding: utf-8 -*-
"""
ç®€å•çš„ ONNX æ¨¡å‹ä¼˜åŒ–è„šæœ¬
ä½¿ç”¨ ONNX ä¼˜åŒ–å™¨è¿›è¡Œå›¾ä¼˜åŒ–å’Œæƒé‡å‹ç¼©
"""

import os
import sys
import io

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º UTF-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

try:
    import onnx
    from onnx import optimizer
    import numpy as np
except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘ä¾èµ–åº“ - {e}")
    print("\nè¯·å…ˆå®‰è£…ä¾èµ–ï¼š")
    print("pip install onnx numpy")
    sys.exit(1)

def optimize_model(input_model, output_model):
    """
    ä½¿ç”¨ ONNX ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
    """
    print("=" * 60)
    print("ğŸŸ Fish Doodle Classifier - ONNX æ¨¡å‹ä¼˜åŒ–å·¥å…·")
    print("=" * 60)
    print(f"\nğŸ“ è¾“å…¥æ¨¡å‹: {input_model}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_model):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {input_model}")
        sys.exit(1)
    
    # è·å–åŸå§‹æ¨¡å‹å¤§å°
    original_size = os.path.getsize(input_model) / (1024 * 1024)
    print(f"ğŸ“Š åŸå§‹æ¨¡å‹å¤§å°: {original_size:.2f} MB")
    
    # åŠ è½½æ¨¡å‹
    print("\nâš™ï¸  æ­£åœ¨åŠ è½½æ¨¡å‹...")
    try:
        model = onnx.load(input_model)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # åº”ç”¨ä¼˜åŒ– passes
    print("\nâš™ï¸  æ­£åœ¨åº”ç”¨ä¼˜åŒ–passes...")
    passes = [
        'eliminate_deadend',
        'eliminate_identity',
        'eliminate_nop_dropout',
        'eliminate_nop_pad',
        'eliminate_nop_transpose',
        'eliminate_unused_initializer',
        'fuse_bn_into_conv',
        'fuse_consecutive_squeezes',
        'fuse_consecutive_transposes',
        'fuse_transpose_into_gemm',
    ]
    
    try:
        optimized_model = optimizer.optimize(model, passes)
        print(f"âœ… å·²åº”ç”¨ {len(passes)} ä¸ªä¼˜åŒ–passes")
    except Exception as e:
        print(f"âš ï¸  ä¼˜åŒ–è­¦å‘Š: {str(e)}")
        optimized_model = model
    
    # ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ä¼˜åŒ–æ¨¡å‹åˆ°: {output_model}")
    try:
        onnx.save(optimized_model, output_model)
        print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ¨¡å‹å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # è·å–ä¼˜åŒ–åæ¨¡å‹å¤§å°
    optimized_size = os.path.getsize(output_model) / (1024 * 1024)
    
    if optimized_size < original_size:
        reduction = ((original_size - optimized_size) / original_size * 100)
        print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
        print(f"   åŸå§‹å¤§å°:  {original_size:.2f} MB")
        print(f"   ä¼˜åŒ–å¤§å°:  {optimized_size:.2f} MB")
        print(f"   å‡å°æ¯”ä¾‹:  {reduction:.1f}%")
        print(f"   èŠ‚çœç©ºé—´:  {original_size - optimized_size:.2f} MB")
    else:
        print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
        print(f"   åŸå§‹å¤§å°:  {original_size:.2f} MB")
        print(f"   ä¼˜åŒ–å¤§å°:  {optimized_size:.2f} MB")
        print(f"   âš ï¸  æ–‡ä»¶å¤§å°æ²¡æœ‰æ˜¾è‘—å‡å°")
    
    # éªŒè¯æ¨¡å‹æ–‡ä»¶
    print("\nğŸ” éªŒè¯ä¼˜åŒ–åçš„æ¨¡å‹...")
    try:
        test_model = onnx.load(output_model)
        onnx.checker.check_model(test_model)
        print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡ï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # ç½‘ç»œæ€§èƒ½ä¼°ç®—
    print("\nğŸ“¡ ç½‘ç»œåŠ è½½æ—¶é—´ä¼°ç®—:")
    print(f"   å¿«é€Ÿ WiFi (50 Mbps):  ~{optimized_size * 8 / 50:.1f} ç§’")
    print(f"   4G ç½‘ç»œ (10 Mbps):     ~{optimized_size * 8 / 10:.1f} ç§’")
    print(f"   æ…¢é€Ÿ 3G (1 Mbps):      ~{optimized_size * 8 / 1 / 60:.1f} åˆ†é’Ÿ")
    
    print("\n" + "=" * 60)
    print("âœ¨ å®Œæˆï¼")
    print("=" * 60)
    
    print("\nğŸ’¡ æç¤º:")
    print("   - å›¾ä¼˜åŒ–ä¸»è¦å‡å°‘æ¨¡å‹ç»“æ„å†—ä½™")
    print("   - å¦‚éœ€è¿›ä¸€æ­¥å‹ç¼©ï¼Œå»ºè®®ä½¿ç”¨ INT8 é‡åŒ–")
    print("   - éœ€è¦ onnxruntime ä¸”æ”¯æŒæ‚¨çš„ Python ç‰ˆæœ¬")

if __name__ == "__main__":
    input_model = "fish_doodle_classifier.onnx"
    output_model = "fish_doodle_classifier_optimized.onnx"
    
    optimize_model(input_model, output_model)


